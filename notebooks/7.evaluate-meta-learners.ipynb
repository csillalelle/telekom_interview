{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Imports and definitions](#imports-and-definitions)\n",
    "2. [Load data and prepare data](#load-data-and-prepare-data)\n",
    "3. [Single Meta Learner Evaluation](#single-meta-learner-evaluation)\n",
    "4. [Segmented Meta Learners Evaluation](#segmented-meta-learners-evaluation)\n",
    "5. [Final Meta Learner (Meta of Metas)](#final-meta-learner-meta-of-metas)\n",
    "6. [Comprehensive Evaluation and Comparison](#comprehensive-evaluation-and-comparison)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, precision_recall_curve, roc_curve, auc,\n",
    "    confusion_matrix, classification_report, matthews_corrcoef\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "import optuna\n",
    "\n",
    "_ = pl.Config.set_tbl_cols(None)\n",
    "_ = pl.Config.set_fmt_str_lengths(500)\n",
    "_ = pl.Config.set_fmt_float(\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, module='sklearn')\n",
    "warnings.filterwarnings('ignore', module='lightgbm')\n",
    "warnings.filterwarnings('ignore', message='X does not have valid feature names, but LGBMClassifier was fitted with feature names')\n",
    "warnings.filterwarnings('ignore', message='bagging_freq is set=6, subsample_freq=0 will be ignored')\n",
    "warnings.filterwarnings('ignore', message='bagging_freq is set=7, subsample_freq=0 will be ignored')\n",
    "warnings.filterwarnings('ignore', message='feature_fraction is set=*')\n",
    "warnings.filterwarnings('ignore', message='bagging_fraction is set=*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('/workspaces/data-scientist-at-magenta')\n",
    "code_dir = base_dir / 'notebooks'\n",
    "data_dir = code_dir / \"data\"\n",
    "features_dir = data_dir / 'features'\n",
    "train_dir = data_dir / 'train'\n",
    "test_dir = data_dir / 'test'\n",
    "db_dir = 'sqlite:///data/models/{}.db'\n",
    "artifacts_dir = data_dir / \"models/artifacts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to load model artifacts\n",
    "def load_model_artifact(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(y_true, y_pred, y_proba=None,\n",
    "                                  model_name=\"Model\", pos_label=1,\n",
    "                                  plot_results=True, print_result=True):\n",
    "    \"\"\"Comprehensive evaluation function for classification models.\"\"\"\n",
    "    y_true_np = y_true.to_numpy()\n",
    "    y_pred_np = y_pred.to_numpy() \n",
    "\n",
    "    results = {'model_name': model_name}\n",
    "\n",
    "    results['accuracy'] = accuracy_score(y_true_np, y_pred_np)\n",
    "    results['precision'] = precision_score(y_true_np, y_pred_np, pos_label=pos_label, average='binary')\n",
    "    results['recall'] = recall_score(y_true_np, y_pred_np, pos_label=pos_label, average='binary')\n",
    "    results['f1_score'] = f1_score(y_true_np, y_pred_np, pos_label=pos_label, average='binary')\n",
    "    results['matthews_corr'] = matthews_corrcoef(y_true_np, y_pred_np)\n",
    "\n",
    "    cm = confusion_matrix(y_true_np, y_pred_np)\n",
    "    results['confusion_matrix'] = cm\n",
    "    results['tn'], results['fp'], results['fn'], results['tp'] = cm.ravel()\n",
    "\n",
    "    if y_proba is not None:\n",
    "        y_proba_np = y_proba.to_numpy()\n",
    "        results['roc_auc'] = roc_auc_score(y_true_np, y_proba_np)\n",
    "        results['pr_auc'] = auc(*precision_recall_curve(y_true_np, y_proba_np)[:2][::-1])\n",
    "\n",
    "    if plot_results:\n",
    "        plot_evaluation_results(y_true_np, y_pred_np, y_proba, model_name, results)\n",
    "\n",
    "    if print_result:\n",
    "        print_evaluation_summary(results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def print_evaluation_summary(results):\n",
    "    \"\"\"Print a formatted summary of evaluation results.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"EVALUATION SUMMARY: {results['model_name']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    print(f\"\\nCORE METRICS:\")\n",
    "    print(f\"  Accuracy:      {results['accuracy']:.4f}\")\n",
    "    print(f\"  Precision:     {results['precision']:.4f}\")\n",
    "    print(f\"  Recall:        {results['recall']:.4f}\")\n",
    "    print(f\"  F1 Score:      {results['f1_score']:.4f}\")\n",
    "    print(f\"  Matthews CC:   {results['matthews_corr']:.4f}\")\n",
    "\n",
    "    if 'roc_auc' in results:\n",
    "        print(f\"\\nPROBABILITY-BASED METRICS:\")\n",
    "        print(f\"  ROC AUC:       {results['roc_auc']:.4f}\")\n",
    "        print(f\"  PR AUC:        {results['pr_auc']:.4f}\")\n",
    "\n",
    "    print(f\"\\nCONFUSION MATRIX:\")\n",
    "    print(f\"  TN: {results['tn']:>6} | FP: {results['fp']:>6}\")\n",
    "    print(f\"  FN: {results['fn']:>6} | TP: {results['tp']:>6}\")\n",
    "\n",
    "\n",
    "def compare_models(models_results):\n",
    "    \"\"\"Compare multiple models and return a comparison DataFrame.\"\"\"\n",
    "    comparison_data = []\n",
    "\n",
    "    for result in models_results:\n",
    "        row = {\n",
    "            'Model': result['model_name'],\n",
    "            'Accuracy': result['accuracy'],\n",
    "            'Precision': result['precision'],\n",
    "            'Recall': result['recall'],\n",
    "            'F1': result['f1_score'],\n",
    "            'Matthews_CC': result['matthews_corr']\n",
    "        }\n",
    "\n",
    "        if 'roc_auc' in result:\n",
    "            row.update({\n",
    "                'ROC_AUC': result['roc_auc'],\n",
    "                'PR_AUC': result['pr_auc']\n",
    "            })\n",
    "\n",
    "        comparison_data.append(row)\n",
    "\n",
    "    comparison_df = pl.DataFrame(comparison_data)\n",
    "    float_cols = [col for col, dtype in comparison_df.schema.items() if dtype == pl.Float64]\n",
    "    comparison_df = comparison_df.with_columns([\n",
    "        pl.col(col).round(4) for col in float_cols\n",
    "    ])\n",
    "    return comparison_df\n",
    "\n",
    "\n",
    "def plot_evaluation_results(y_true, y_pred, y_proba, model_name, results):\n",
    "    \"\"\"Generate comprehensive evaluation plots using Plotly.\"\"\"\n",
    "    cm = results['confusion_matrix']\n",
    "    fig_cm = go.Figure(data=go.Heatmap(\n",
    "        z=cm,\n",
    "        x=['Predicted 0', 'Predicted 1'],\n",
    "        y=['Actual 0', 'Actual 1'],\n",
    "        colorscale='Blues',\n",
    "        text=cm,\n",
    "        texttemplate=\"%{text}\",\n",
    "        textfont={\"size\": 20}\n",
    "    ))\n",
    "    fig_cm.update_layout(\n",
    "        title=f'Confusion Matrix: {model_name}',\n",
    "        xaxis_title='Predicted',\n",
    "        yaxis_title='Actual',\n",
    "        height=400, width=500\n",
    "    )\n",
    "    fig_cm.show()\n",
    "\n",
    "\n",
    "def create_bins_split_features(X, y, split_configs, base_models, seed=42):\n",
    "    \"\"\"Create bins split features based on different column thresholds.\"\"\"\n",
    "    predictions_dict = {}\n",
    "    \n",
    "    for config in split_configs:\n",
    "        name = config['name']\n",
    "        column = config['column']\n",
    "        threshold = config['threshold']\n",
    "        \n",
    "        model_b1, model_b2 = base_models[name]\n",
    "        predictions = np.zeros(X.height)\n",
    "        \n",
    "        column_values = X.select(column).to_numpy().ravel()\n",
    "        b1_mask = column_values < threshold\n",
    "        b2_mask = ~b1_mask\n",
    "        \n",
    "        X_for_prediction = X.drop(column).with_row_index(\"idx\")\n",
    "        \n",
    "        if np.any(b1_mask):\n",
    "            b1_indices = np.where(b1_mask)[0]\n",
    "            b1_X = X_for_prediction.filter(pl.col(\"idx\").is_in(b1_indices)).drop(\"idx\")\n",
    "            b1_predictions = model_b1.predict(b1_X.to_numpy())\n",
    "            predictions[b1_mask] = b1_predictions\n",
    "        \n",
    "        if np.any(b2_mask):\n",
    "            b2_indices = np.where(b2_mask)[0]\n",
    "            b2_X = X_for_prediction.filter(pl.col(\"idx\").is_in(b2_indices)).drop(\"idx\")\n",
    "            b2_predictions = model_b2.predict(b2_X.to_numpy())\n",
    "            predictions[b2_mask] = b2_predictions\n",
    "        \n",
    "        predictions_dict[name] = predictions\n",
    "    \n",
    "    predictions_dict['label'] = y.to_numpy().ravel()\n",
    "    final_df = pl.DataFrame(predictions_dict)\n",
    "    return final_df.sample(fraction=1.0, with_replacement=False, seed=seed)\n",
    "\n",
    "\n",
    "def ridge_from_study_path(study_path, study_name):\n",
    "    \"\"\"Helper to extract best params and create RidgeClassifier\"\"\"\n",
    "    study = optuna.load_study(study_name=study_name, storage=study_path)\n",
    "    params = study.best_params.copy()\n",
    "    valid_keys = {'alpha', 'solver', 'class_weight'}\n",
    "    params = {k: v for k, v in params.items() if k in valid_keys}\n",
    "    return RidgeClassifier(**params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pl.read_parquet(test_dir / 'data-meta-v0-50.parquet')\n",
    "X_test = test.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_test = test.select('has_done_upselling')\n",
    "\n",
    "X_meta, X_final_meta, y_meta, y_final_meta = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "train__final_meta = pl.concat([X_meta, y_meta], how='horizontal')\n",
    "final_test = pl.concat([X_final_meta, y_final_meta], how='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base = pl.read_parquet(train_dir / 'data-v0-80.parquet')\n",
    "train_meta = pl.read_parquet(train_dir / 'data-meta-v0-50.parquet')\n",
    "\n",
    "\n",
    "train = pl.concat([train_base, train_meta, train__final_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (95000, 49)\n",
      "Test set shape: (5000, 49)\n"
     ]
    }
   ],
   "source": [
    "X_train = train.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train = train.select('has_done_upselling')\n",
    "\n",
    "X_test = final_test.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_test = final_test.select('has_done_upselling')\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Test set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Single Meta Learner Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model studies...\n",
      "Training base models...\n",
      "Single meta learner trained!\n"
     ]
    }
   ],
   "source": [
    "# Load base model studies and create single meta learner\n",
    "print(\"Loading base model studies...\")\n",
    "xgb_study = optuna.load_study(study_name=\"xgboost_optimization\", storage=db_dir.format('xgb_study'))\n",
    "rf_study = optuna.load_study(study_name=\"random_forest_optimization_basef1\", storage=db_dir.format('rf_study'))\n",
    "histgb_study = optuna.load_study(study_name=\"histgb_optimization\", storage=db_dir.format('histgb_study'))\n",
    "cat_study = optuna.load_study(study_name=\"catboost_optimization\", storage=db_dir.format('cat_study'))\n",
    "meta_study = optuna.load_study(study_name=\"meta_ridge_base_optimization\", storage=db_dir.format('meta_learners_study'))\n",
    "\n",
    "# Create and train base models\n",
    "print(\"Training base models...\")\n",
    "X_np, y_np = X_train.to_numpy(), y_train.to_numpy().ravel()\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(**xgb_study.best_params).fit(X_np, y_np)\n",
    "rf_model = RandomForestClassifier(**rf_study.best_params).fit(X_np, y_np)\n",
    "histgb_model = HistGradientBoostingClassifier(**histgb_study.best_params).fit(X_np, y_np)\n",
    "cat_model = CatBoostClassifier(**cat_study.best_params, verbose=0).fit(X_np, y_np)\n",
    "\n",
    "# Create single stacking classifier\n",
    "single_stacking_clf = StackingClassifier(\n",
    "    estimators=[(\"xgb\", xgb_model), (\"rf\", rf_model), (\"histgb\", histgb_model), (\"cat\", cat_model)],\n",
    "    final_estimator=RidgeClassifier(**meta_study.best_params),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ").fit(X_np, y_np)\n",
    "\n",
    "print(\"Single meta learner trained!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Single Meta Learner (Stacking)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.6486\n",
      "  Precision:     0.0916\n",
      "  Recall:        0.4398\n",
      "  F1 Score:      0.1516\n",
      "  Matthews CC:   0.0567\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3086 | FP:   1557\n",
      "  FN:    200 | TP:    157\n",
      "\n",
      "============================================================\n",
      "EVALUATING INDIVIDUAL BASE MODELS WITH BEST THRESHOLDS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: XGBoost (Best Threshold)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7362\n",
      "  Precision:     0.1012\n",
      "  Recall:        0.3417\n",
      "  F1 Score:      0.1561\n",
      "  Matthews CC:   0.0652\n",
      "\n",
      "PROBABILITY-BASED METRICS:\n",
      "  ROC AUC:       0.5948\n",
      "  PR AUC:        0.0924\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3559 | FP:   1084\n",
      "  FN:    235 | TP:    122\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Random Forest (Base Threshold)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.6344\n",
      "  Precision:     0.1009\n",
      "  Recall:        0.5210\n",
      "  F1 Score:      0.1691\n",
      "  Matthews CC:   0.0876\n",
      "\n",
      "PROBABILITY-BASED METRICS:\n",
      "  ROC AUC:       0.6335\n",
      "  PR AUC:        0.1138\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   2986 | FP:   1657\n",
      "  FN:    171 | TP:    186\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: HistGradientBoosting (Best Threshold)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.6752\n",
      "  Precision:     0.0993\n",
      "  Recall:        0.4398\n",
      "  F1 Score:      0.1620\n",
      "  Matthews CC:   0.0737\n",
      "\n",
      "PROBABILITY-BASED METRICS:\n",
      "  ROC AUC:       0.6191\n",
      "  PR AUC:        0.1114\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3219 | FP:   1424\n",
      "  FN:    200 | TP:    157\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: CatBoost (Best Threshold)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7134\n",
      "  Precision:     0.1129\n",
      "  Recall:        0.4398\n",
      "  F1 Score:      0.1797\n",
      "  Matthews CC:   0.1001\n",
      "\n",
      "PROBABILITY-BASED METRICS:\n",
      "  ROC AUC:       0.6354\n",
      "  PR AUC:        0.1110\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3410 | FP:   1233\n",
      "  FN:    200 | TP:    157\n"
     ]
    }
   ],
   "source": [
    "# Evaluate single meta learner and individual base models\n",
    "y_pred_single = single_stacking_clf.predict(X_test.to_numpy())\n",
    "y_true_pl = pl.Series(\"y_true\", y_test.to_numpy().ravel())\n",
    "y_pred_single_pl = pl.Series(\"y_pred\", y_pred_single)\n",
    "\n",
    "results_single = evaluate_classification_model(\n",
    "    y_true=y_true_pl, y_pred=y_pred_single_pl, y_proba=None,\n",
    "    model_name=\"Single Meta Learner (Stacking)\", plot_results=False, print_result=True\n",
    ")\n",
    "\n",
    "# Initialize results list with single meta learner\n",
    "results_list = [results_single]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING INDIVIDUAL BASE MODELS WITH BEST THRESHOLDS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "best_thresholds = {\n",
    "    'xgb': xgb_study.best_trial.user_attrs.get('threshold', 0.5),\n",
    "    'cat': cat_study.best_trial.user_attrs.get('threshold', 0.5),\n",
    "    'hgb': histgb_study.best_trial.user_attrs.get('threshold', 0.5)\n",
    "}\n",
    "\n",
    "# Evaluate XGBoost with best threshold\n",
    "y_proba_xgb = xgb_model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred_xgb = (y_proba_xgb > best_thresholds['xgb']).astype(int)\n",
    "results_xgb = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_xgb),\n",
    "    y_proba=pl.Series(\"y_proba\", y_proba_xgb), \n",
    "    model_name=\"XGBoost (Best Threshold)\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_xgb)\n",
    "\n",
    "# Evaluate Random Forest with base threshold\n",
    "y_proba_rf = rf_model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred_rf = (y_proba_rf > 0.5).astype(int)\n",
    "results_rf = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_rf),\n",
    "    y_proba=pl.Series(\"y_proba\", y_proba_rf),\n",
    "    model_name=\"Random Forest (Base Threshold)\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_rf)\n",
    "\n",
    "# Evaluate HistGradientBoosting with best threshold\n",
    "y_proba_histgb = histgb_model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred_histgb = (y_proba_histgb > best_thresholds['hgb']).astype(int)\n",
    "results_histgb = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_histgb),\n",
    "    y_proba=pl.Series(\"y_proba\", y_proba_histgb),\n",
    "    model_name=\"HistGradientBoosting (Best Threshold)\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_histgb)\n",
    "\n",
    "# Evaluate CatBoost with best threshold\n",
    "y_proba_cat = cat_model.predict_proba(X_test.to_numpy())[:, 1]\n",
    "y_pred_cat = (y_proba_cat > best_thresholds['cat']).astype(int)\n",
    "results_cat = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_cat),\n",
    "    y_proba=pl.Series(\"y_proba\", y_proba_cat),\n",
    "    model_name=\"CatBoost (Best Threshold)\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Segmented Meta Learners Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading segmented models...\n",
      "Loaded models - Age: B1(4), B2(3)\n",
      "                Days: B1(3), B2(3)\n",
      "                Data: B1(2), B2(2)\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained segmented models\n",
    "print(\"Loading segmented models...\")\n",
    "\n",
    "# Age models\n",
    "base_models_age_b1 = [\n",
    "    ('xg_age_b1', load_model_artifact(artifacts_dir / \"pre_xgb_age_b1.pkl\")),\n",
    "    ('rf_clf_age_b1', load_model_artifact(artifacts_dir / \"pre_rf_age_b1.pkl\")),\n",
    "    ('cat_clf_age_b1', load_model_artifact(artifacts_dir / \"pre_cat_age_b1.pkl\")),\n",
    "    ('histgb_age_b1', load_model_artifact(artifacts_dir / \"pre_histgb_age_b1.pkl\"))\n",
    "]\n",
    "base_models_age_b2 = [\n",
    "    ('xg_age_b2', load_model_artifact(artifacts_dir / \"pre_xgb_age_b2.pkl\")),\n",
    "    ('rf_clf_age_b2', load_model_artifact(artifacts_dir / \"pre_rf_age_b2.pkl\")),\n",
    "    ('histgb_age_b2', load_model_artifact(artifacts_dir / \"pre_histgb_age_b2.pkl\"))\n",
    "\n",
    "]\n",
    "\n",
    "# Days models  \n",
    "base_models_days_b1 = [\n",
    "    ('rf_days_b1', load_model_artifact(artifacts_dir / \"pre_rf_days_b1.pkl\")),\n",
    "    ('lgb_days_b1', load_model_artifact(artifacts_dir / \"pre_lgb_days_b1.pkl\")),\n",
    "    ('cat_days_b1', load_model_artifact(artifacts_dir / \"pre_cat_days_b1.pkl\"))\n",
    "]\n",
    "base_models_days_b2 = [\n",
    "    ('rf_days_b2', load_model_artifact(artifacts_dir / \"pre_rf_days_b2.pkl\")),\n",
    "    ('lgb_days_b2', load_model_artifact(artifacts_dir / \"pre_lgb_days_b2.pkl\")),\n",
    "    ('cat_days_b2', load_model_artifact(artifacts_dir / \"pre_cat_days_b2.pkl\"))\n",
    "]\n",
    "\n",
    "# Data models\n",
    "base_models_data_b1 = [\n",
    "    ('xgb_data_b1', load_model_artifact(artifacts_dir / \"pre_xgb_data_b1.pkl\")),\n",
    "    ('cat_data_b1', load_model_artifact(artifacts_dir / \"pre_cat_data_b1.pkl\"))\n",
    "]\n",
    "base_models_data_b2 = [\n",
    "    ('xgb_data_b2', load_model_artifact(artifacts_dir / \"pre_xgb_data_b2.pkl\")),\n",
    "    ('cat_data_b2', load_model_artifact(artifacts_dir / \"pre_cat_data_b2.pkl\"))\n",
    "]\n",
    "\n",
    "print(f\"Loaded models - Age: B1({len(base_models_age_b1)}), B2({len(base_models_age_b2)})\")\n",
    "print(f\"                Days: B1({len(base_models_days_b1)}), B2({len(base_models_days_b2)})\")  \n",
    "print(f\"                Data: B1({len(base_models_data_b1)}), B2({len(base_models_data_b2)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating segmented stackers...\n",
      "Segmented stackers created!\n"
     ]
    }
   ],
   "source": [
    "# Create and train segmented stacking classifiers\n",
    "print(\"Creating segmented stackers...\")\n",
    "\n",
    "# Create stackers\n",
    "stacking_age_b1 = StackingClassifier(\n",
    "    estimators=base_models_age_b1,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b1_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "stacking_age_b2 = StackingClassifier(\n",
    "    estimators=base_models_age_b2,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b2_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "stacking_days_b1 = StackingClassifier(\n",
    "    estimators=base_models_days_b1,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b1_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "stacking_days_b2 = StackingClassifier(\n",
    "    estimators=base_models_days_b2,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b2_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "stacking_data_b1 = StackingClassifier(\n",
    "    estimators=base_models_data_b1,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b1_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "stacking_data_b2 = StackingClassifier(\n",
    "    estimators=base_models_data_b2,\n",
    "    final_estimator=ridge_from_study_path(db_dir.format('meta_learners_study'), \"meta_ridge_age_b2_optimization\"),\n",
    "    cv='prefit', stack_method='predict_proba'\n",
    ")\n",
    "\n",
    "print(\"Segmented stackers created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing segment training data...\n",
      "Segment training data prepared!\n"
     ]
    }
   ],
   "source": [
    "# Use the train data prepared at the beginning instead of creating new split\n",
    "train_meta = train\n",
    "\n",
    "# Create segment training data using the full train set\n",
    "print(\"Preparing segment training data...\")\n",
    "data_age_b1 = train_meta.filter(pl.col(\"age\") < 55).drop('age')\n",
    "data_age_b2 = train_meta.filter(pl.col(\"age\") >= 55).drop('age')\n",
    "\n",
    "data_days_b1 = train_meta.filter(pl.col(\"contract_lifetime_days\") < 1000).drop('contract_lifetime_days')\n",
    "data_days_b2 = train_meta.filter(pl.col(\"contract_lifetime_days\") >= 1000).drop('contract_lifetime_days')\n",
    "\n",
    "data_data_b1 = train_meta.filter(pl.col(\"available_gb\") < 25).drop('available_gb')\n",
    "data_data_b2 = train_meta.filter(pl.col(\"available_gb\") >= 25).drop('available_gb')\n",
    "\n",
    "# Extract features and labels\n",
    "X_train_age_b1 = data_age_b1.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_age_b1 = data_age_b1.select('has_done_upselling')\n",
    "X_train_age_b2 = data_age_b2.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_age_b2 = data_age_b2.select('has_done_upselling')\n",
    "\n",
    "X_train_days_b1 = data_days_b1.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_days_b1 = data_days_b1.select('has_done_upselling')\n",
    "X_train_days_b2 = data_days_b2.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_days_b2 = data_days_b2.select('has_done_upselling')\n",
    "\n",
    "X_train_data_b1 = data_data_b1.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_data_b1 = data_data_b1.select('has_done_upselling')\n",
    "X_train_data_b2 = data_data_b2.select(pl.exclude(['rating_account_id', 'customer_id', 'has_done_upselling']))\n",
    "y_train_data_b2 = data_data_b2.select('has_done_upselling')\n",
    "\n",
    "print(\"Segment training data prepared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training segmented stackers...\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "All segmented stackers trained!\n"
     ]
    }
   ],
   "source": [
    "# Train segmented stackers\n",
    "print(\"Training segmented stackers...\")\n",
    "stacking_age_b1.fit(X_train_age_b1.to_numpy(), y_train_age_b1.to_numpy().ravel())\n",
    "stacking_age_b2.fit(X_train_age_b2.to_numpy(), y_train_age_b2.to_numpy().ravel())\n",
    "stacking_days_b1.fit(X_train_days_b1.to_numpy(), y_train_days_b1.to_numpy().ravel())\n",
    "stacking_days_b2.fit(X_train_days_b2.to_numpy(), y_train_days_b2.to_numpy().ravel())\n",
    "stacking_data_b1.fit(X_train_data_b1.to_numpy(), y_train_data_b1.to_numpy().ravel())\n",
    "stacking_data_b2.fit(X_train_data_b2.to_numpy(), y_train_data_b2.to_numpy().ravel())\n",
    "print(\"All segmented stackers trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Final Meta Learner (Meta of Metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating final meta learner...\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "Final meta learner trained!\n"
     ]
    }
   ],
   "source": [
    "# Create and train final meta learner\n",
    "print(\"Creating final meta learner...\")\n",
    "final_meta_study = optuna.load_study(\n",
    "    study_name=\"meta_ridge_final_decision_optimization\",\n",
    "    storage=db_dir.format('meta_learners_study')\n",
    ")\n",
    "\n",
    "split_configs = [\n",
    "    {'name': 'age', 'column': 'age', 'threshold': 55},\n",
    "    {'name': 'days', 'column': 'contract_lifetime_days', 'threshold': 1000}, \n",
    "    {'name': 'data', 'column': 'available_gb', 'threshold': 25}\n",
    "]\n",
    "\n",
    "base_models_dict = {\n",
    "    'age': (stacking_age_b1, stacking_age_b2),\n",
    "    'days': (stacking_days_b1, stacking_days_b2),\n",
    "    'data': (stacking_data_b1, stacking_data_b2)\n",
    "}\n",
    "\n",
    "# Train final meta learner on the split\n",
    "meta_train_X_y = create_bins_split_features(X_train, y_train, split_configs, base_models_dict)\n",
    "final_meta_params = {k: v for k, v in final_meta_study.best_params.items() if k in {'alpha', 'solver', 'class_weight'}}\n",
    "final_meta_clf = RidgeClassifier(**final_meta_params)\n",
    "final_meta_clf.fit(meta_train_X_y.select(['age', 'days', 'data']).to_numpy(), \n",
    "                   meta_train_X_y.select('label').to_numpy().ravel())\n",
    "\n",
    "print(\"Final meta learner trained!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Comprehensive Evaluation and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating final meta learner...\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Final Meta Learner (Meta of Metas)\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7270\n",
      "  Precision:     0.0929\n",
      "  Recall:        0.3221\n",
      "  F1 Score:      0.1442\n",
      "  Matthews CC:   0.0479\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3520 | FP:   1123\n",
      "  FN:    242 | TP:    115\n"
     ]
    }
   ],
   "source": [
    "# Evaluate final meta learner\n",
    "print(\"Evaluating final meta learner...\")\n",
    "meta_test_X_y = create_bins_split_features(X_test, y_test, split_configs, base_models_dict)\n",
    "y_pred_final = final_meta_clf.predict(meta_test_X_y.select(['age', 'days', 'data']).to_numpy())\n",
    "\n",
    "results_final = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_final),\n",
    "    y_proba=None,\n",
    "    model_name=\"Final Meta Learner (Meta of Metas)\",\n",
    "    plot_results=False,\n",
    "    print_result=True\n",
    ")\n",
    "\n",
    "# Add final meta learner to results list \n",
    "results_list.append(results_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUATING SINGLE-DIMENSION SEGMENTED META LEARNERS\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Age-based Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7078\n",
      "  Precision:     0.1023\n",
      "  Recall:        0.3978\n",
      "  F1 Score:      0.1628\n",
      "  Matthews CC:   0.0744\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3397 | FP:   1246\n",
      "  FN:    215 | TP:    142\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Days-based Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7270\n",
      "  Precision:     0.0929\n",
      "  Recall:        0.3221\n",
      "  F1 Score:      0.1442\n",
      "  Matthews CC:   0.0479\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3520 | FP:   1123\n",
      "  FN:    242 | TP:    115\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Data-based Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.6052\n",
      "  Precision:     0.0902\n",
      "  Recall:        0.4986\n",
      "  F1 Score:      0.1528\n",
      "  Matthews CC:   0.0590\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   2848 | FP:   1795\n",
      "  FN:    179 | TP:    178\n",
      "\n",
      "============================================================\n",
      "EVALUATING MULTI-DIMENSIONAL SEGMENTED META LEARNERS\n",
      "============================================================\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Age-Days Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7078\n",
      "  Precision:     0.1023\n",
      "  Recall:        0.3978\n",
      "  F1 Score:      0.1628\n",
      "  Matthews CC:   0.0744\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3397 | FP:   1246\n",
      "  FN:    215 | TP:    142\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Age-Data Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7078\n",
      "  Precision:     0.1023\n",
      "  Recall:        0.3978\n",
      "  F1 Score:      0.1628\n",
      "  Matthews CC:   0.0744\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3397 | FP:   1246\n",
      "  FN:    215 | TP:    142\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8151925596377104, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8151925596377104\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9704150221294421, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9704150221294421\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8162034579535279, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8162034579535279\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9276862426700836, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9276862426700836\n",
      "\n",
      "============================================================\n",
      "EVALUATION SUMMARY: Days-Data Meta Learner\n",
      "============================================================\n",
      "\n",
      "CORE METRICS:\n",
      "  Accuracy:      0.7270\n",
      "  Precision:     0.0929\n",
      "  Recall:        0.3221\n",
      "  F1 Score:      0.1442\n",
      "  Matthews CC:   0.0479\n",
      "\n",
      "CONFUSION MATRIX:\n",
      "  TN:   3520 | FP:   1123\n",
      "  FN:    242 | TP:    115\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING SINGLE-DIMENSION SEGMENTED META LEARNERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Age-based meta learner using create_bins_split_features\n",
    "age_split_config = [{'name': 'age', 'column': 'age', 'threshold': 55}]\n",
    "age_base_models = {'age': (stacking_age_b1, stacking_age_b2)}\n",
    "\n",
    "age_test_features = create_bins_split_features(X_test, y_test, age_split_config, age_base_models)\n",
    "y_pred_age_meta = age_test_features.select('age').to_numpy().ravel()\n",
    "\n",
    "results_age_meta = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_age_meta),\n",
    "    y_proba=None, model_name=\"Age-based Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_age_meta)\n",
    "\n",
    "# Days-based meta learner using create_bins_split_features\n",
    "days_split_config = [{'name': 'days', 'column': 'contract_lifetime_days', 'threshold': 1000}]\n",
    "days_base_models = {'days': (stacking_days_b1, stacking_days_b2)}\n",
    "\n",
    "days_test_features = create_bins_split_features(X_test, y_test, days_split_config, days_base_models)\n",
    "y_pred_days_meta = days_test_features.select('days').to_numpy().ravel()\n",
    "\n",
    "results_days_meta = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_days_meta),\n",
    "    y_proba=None, model_name=\"Days-based Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_days_meta)\n",
    "\n",
    "# Data-based meta learner using create_bins_split_features\n",
    "data_split_config = [{'name': 'data', 'column': 'available_gb', 'threshold': 25}]\n",
    "data_base_models = {'data': (stacking_data_b1, stacking_data_b2)}\n",
    "\n",
    "data_test_features = create_bins_split_features(X_test, y_test, data_split_config, data_base_models)\n",
    "y_pred_data_meta = data_test_features.select('data').to_numpy().ravel()\n",
    "\n",
    "results_data_meta = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_data_meta),\n",
    "    y_proba=None, model_name=\"Data-based Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_data_meta)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUATING MULTI-DIMENSIONAL SEGMENTED META LEARNERS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Age-Days combination using create_bins_split_features\n",
    "age_days_split_config = [\n",
    "    {'name': 'age', 'column': 'age', 'threshold': 55},\n",
    "    {'name': 'days', 'column': 'contract_lifetime_days', 'threshold': 1000}\n",
    "]\n",
    "age_days_base_models = {\n",
    "    'age': (stacking_age_b1, stacking_age_b2),\n",
    "    'days': (stacking_days_b1, stacking_days_b2)\n",
    "}\n",
    "\n",
    "age_days_test_features = create_bins_split_features(X_test, y_test, age_days_split_config, age_days_base_models)\n",
    "# Use age predictions as the final prediction for Age-Days meta learner\n",
    "y_pred_age_days = age_days_test_features.select('age').to_numpy().ravel()\n",
    "\n",
    "results_age_days = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_age_days),\n",
    "    y_proba=None, model_name=\"Age-Days Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_age_days)\n",
    "\n",
    "# Age-Data combination using create_bins_split_features\n",
    "age_data_split_config = [\n",
    "    {'name': 'age', 'column': 'age', 'threshold': 55},\n",
    "    {'name': 'data', 'column': 'available_gb', 'threshold': 25}\n",
    "]\n",
    "age_data_base_models = {\n",
    "    'age': (stacking_age_b1, stacking_age_b2),\n",
    "    'data': (stacking_data_b1, stacking_data_b2)\n",
    "}\n",
    "\n",
    "age_data_test_features = create_bins_split_features(X_test, y_test, age_data_split_config, age_data_base_models)\n",
    "# Use age predictions as the final prediction for Age-Data meta learner\n",
    "y_pred_age_data = age_data_test_features.select('age').to_numpy().ravel()\n",
    "\n",
    "results_age_data = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_age_data),\n",
    "    y_proba=None, model_name=\"Age-Data Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_age_data)\n",
    "\n",
    "# Days-Data combination using create_bins_split_features\n",
    "days_data_split_config = [\n",
    "    {'name': 'days', 'column': 'contract_lifetime_days', 'threshold': 1000},\n",
    "    {'name': 'data', 'column': 'available_gb', 'threshold': 25}\n",
    "]\n",
    "days_data_base_models = {\n",
    "    'days': (stacking_days_b1, stacking_days_b2),\n",
    "    'data': (stacking_data_b1, stacking_data_b2)\n",
    "}\n",
    "\n",
    "days_data_test_features = create_bins_split_features(X_test, y_test, days_data_split_config, days_data_base_models)\n",
    "# Use days predictions as the final prediction for Days-Data meta learner\n",
    "y_pred_days_data = days_data_test_features.select('days').to_numpy().ravel()\n",
    "\n",
    "results_days_data = evaluate_classification_model(\n",
    "    y_true=y_true_pl,\n",
    "    y_pred=pl.Series(\"y_pred\", y_pred_days_data),\n",
    "    y_proba=None, model_name=\"Days-Data Meta Learner\",\n",
    "    plot_results=False, print_result=True\n",
    ")\n",
    "results_list.append(results_days_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL COMPARISON OF ALL META LEARNERS\n",
      "================================================================================\n",
      "shape: (12, 8)\n",
      "┌────────────────────────┬──────────┬───────────┬────────┬────────┬─────────────┬─────────┬────────┐\n",
      "│ Model                  ┆ Accuracy ┆ Precision ┆ Recall ┆ F1     ┆ Matthews_CC ┆ ROC_AUC ┆ PR_AUC │\n",
      "│ ---                    ┆ ---      ┆ ---       ┆ ---    ┆ ---    ┆ ---         ┆ ---     ┆ ---    │\n",
      "│ str                    ┆ f64      ┆ f64       ┆ f64    ┆ f64    ┆ f64         ┆ f64     ┆ f64    │\n",
      "╞════════════════════════╪══════════╪═══════════╪════════╪════════╪═════════════╪═════════╪════════╡\n",
      "│ Single Meta Learner    ┆ 0.6486   ┆ 0.0916    ┆ 0.4398 ┆ 0.1516 ┆ 0.0567      ┆ null    ┆ null   │\n",
      "│ (Stacking)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ XGBoost (Best          ┆ 0.7362   ┆ 0.1012    ┆ 0.3417 ┆ 0.1561 ┆ 0.0652      ┆ 0.5948  ┆ 0.0924 │\n",
      "│ Threshold)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Random Forest (Base    ┆ 0.6344   ┆ 0.1009    ┆ 0.521  ┆ 0.1691 ┆ 0.0876      ┆ 0.6335  ┆ 0.1138 │\n",
      "│ Threshold)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ HistGradientBoosting   ┆ 0.6752   ┆ 0.0993    ┆ 0.4398 ┆ 0.162  ┆ 0.0737      ┆ 0.6191  ┆ 0.1114 │\n",
      "│ (Best Threshold)       ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ CatBoost (Best         ┆ 0.7134   ┆ 0.1129    ┆ 0.4398 ┆ 0.1797 ┆ 0.1001      ┆ 0.6354  ┆ 0.111  │\n",
      "│ Threshold)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ …                      ┆ …        ┆ …         ┆ …      ┆ …      ┆ …           ┆ …       ┆ …      │\n",
      "│ Days-based Meta        ┆ 0.727    ┆ 0.0929    ┆ 0.3221 ┆ 0.1442 ┆ 0.0479      ┆ null    ┆ null   │\n",
      "│ Learner                ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Data-based Meta        ┆ 0.6052   ┆ 0.0902    ┆ 0.4986 ┆ 0.1528 ┆ 0.059       ┆ null    ┆ null   │\n",
      "│ Learner                ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Age-Days Meta Learner  ┆ 0.7078   ┆ 0.1023    ┆ 0.3978 ┆ 0.1628 ┆ 0.0744      ┆ null    ┆ null   │\n",
      "│ Age-Data Meta Learner  ┆ 0.7078   ┆ 0.1023    ┆ 0.3978 ┆ 0.1628 ┆ 0.0744      ┆ null    ┆ null   │\n",
      "│ Days-Data Meta Learner ┆ 0.727    ┆ 0.0929    ┆ 0.3221 ┆ 0.1442 ┆ 0.0479      ┆ null    ┆ null   │\n",
      "└────────────────────────┴──────────┴───────────┴────────┴────────┴─────────────┴─────────┴────────┘\n",
      "\n",
      "================================================================================\n",
      "RANKED BY F1 SCORE:\n",
      "================================================================================\n",
      "shape: (12, 8)\n",
      "┌────────────────────────┬──────────┬───────────┬────────┬────────┬─────────────┬─────────┬────────┐\n",
      "│ Model                  ┆ Accuracy ┆ Precision ┆ Recall ┆ F1     ┆ Matthews_CC ┆ ROC_AUC ┆ PR_AUC │\n",
      "│ ---                    ┆ ---      ┆ ---       ┆ ---    ┆ ---    ┆ ---         ┆ ---     ┆ ---    │\n",
      "│ str                    ┆ f64      ┆ f64       ┆ f64    ┆ f64    ┆ f64         ┆ f64     ┆ f64    │\n",
      "╞════════════════════════╪══════════╪═══════════╪════════╪════════╪═════════════╪═════════╪════════╡\n",
      "│ CatBoost (Best         ┆ 0.7134   ┆ 0.1129    ┆ 0.4398 ┆ 0.1797 ┆ 0.1001      ┆ 0.6354  ┆ 0.111  │\n",
      "│ Threshold)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Random Forest (Base    ┆ 0.6344   ┆ 0.1009    ┆ 0.521  ┆ 0.1691 ┆ 0.0876      ┆ 0.6335  ┆ 0.1138 │\n",
      "│ Threshold)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Age-based Meta Learner ┆ 0.7078   ┆ 0.1023    ┆ 0.3978 ┆ 0.1628 ┆ 0.0744      ┆ null    ┆ null   │\n",
      "│ Age-Days Meta Learner  ┆ 0.7078   ┆ 0.1023    ┆ 0.3978 ┆ 0.1628 ┆ 0.0744      ┆ null    ┆ null   │\n",
      "│ Age-Data Meta Learner  ┆ 0.7078   ┆ 0.1023    ┆ 0.3978 ┆ 0.1628 ┆ 0.0744      ┆ null    ┆ null   │\n",
      "│ …                      ┆ …        ┆ …         ┆ …      ┆ …      ┆ …           ┆ …       ┆ …      │\n",
      "│ Data-based Meta        ┆ 0.6052   ┆ 0.0902    ┆ 0.4986 ┆ 0.1528 ┆ 0.059       ┆ null    ┆ null   │\n",
      "│ Learner                ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Single Meta Learner    ┆ 0.6486   ┆ 0.0916    ┆ 0.4398 ┆ 0.1516 ┆ 0.0567      ┆ null    ┆ null   │\n",
      "│ (Stacking)             ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Final Meta Learner     ┆ 0.727    ┆ 0.0929    ┆ 0.3221 ┆ 0.1442 ┆ 0.0479      ┆ null    ┆ null   │\n",
      "│ (Meta of Metas)        ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Days-based Meta        ┆ 0.727    ┆ 0.0929    ┆ 0.3221 ┆ 0.1442 ┆ 0.0479      ┆ null    ┆ null   │\n",
      "│ Learner                ┆          ┆           ┆        ┆        ┆             ┆         ┆        │\n",
      "│ Days-Data Meta Learner ┆ 0.727    ┆ 0.0929    ┆ 0.3221 ┆ 0.1442 ┆ 0.0479      ┆ null    ┆ null   │\n",
      "└────────────────────────┴──────────┴───────────┴────────┴────────┴─────────────┴─────────┴────────┘\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "marker": {
          "color": "#1f77b4"
         },
         "name": "Accuracy",
         "offsetgroup": "0",
         "type": "bar",
         "x": [
          "CatBoost (Best Threshold)",
          "Random Forest (Base Threshold)",
          "Age-based Meta Learner",
          "Age-Days Meta Learner",
          "Age-Data Meta Learner",
          "HistGradientBoosting (Best Threshold)",
          "XGBoost (Best Threshold)",
          "Data-based Meta Learner",
          "Single Meta Learner (Stacking)",
          "Final Meta Learner (Meta of Metas)",
          "Days-based Meta Learner",
          "Days-Data Meta Learner"
         ],
         "y": [
          0.7134,
          0.6344,
          0.7078,
          0.7078,
          0.7078,
          0.6752,
          0.7362,
          0.6052,
          0.6486,
          0.727,
          0.727,
          0.727
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#ff7f0e"
         },
         "name": "Precision",
         "offsetgroup": "1",
         "type": "bar",
         "x": [
          "CatBoost (Best Threshold)",
          "Random Forest (Base Threshold)",
          "Age-based Meta Learner",
          "Age-Days Meta Learner",
          "Age-Data Meta Learner",
          "HistGradientBoosting (Best Threshold)",
          "XGBoost (Best Threshold)",
          "Data-based Meta Learner",
          "Single Meta Learner (Stacking)",
          "Final Meta Learner (Meta of Metas)",
          "Days-based Meta Learner",
          "Days-Data Meta Learner"
         ],
         "y": [
          0.1129,
          0.1009,
          0.1023,
          0.1023,
          0.1023,
          0.0993,
          0.1012,
          0.0902,
          0.0916,
          0.0929,
          0.0929,
          0.0929
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#2ca02c"
         },
         "name": "Recall",
         "offsetgroup": "2",
         "type": "bar",
         "x": [
          "CatBoost (Best Threshold)",
          "Random Forest (Base Threshold)",
          "Age-based Meta Learner",
          "Age-Days Meta Learner",
          "Age-Data Meta Learner",
          "HistGradientBoosting (Best Threshold)",
          "XGBoost (Best Threshold)",
          "Data-based Meta Learner",
          "Single Meta Learner (Stacking)",
          "Final Meta Learner (Meta of Metas)",
          "Days-based Meta Learner",
          "Days-Data Meta Learner"
         ],
         "y": [
          0.4398,
          0.521,
          0.3978,
          0.3978,
          0.3978,
          0.4398,
          0.3417,
          0.4986,
          0.4398,
          0.3221,
          0.3221,
          0.3221
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#d62728"
         },
         "name": "F1",
         "offsetgroup": "3",
         "type": "bar",
         "x": [
          "CatBoost (Best Threshold)",
          "Random Forest (Base Threshold)",
          "Age-based Meta Learner",
          "Age-Days Meta Learner",
          "Age-Data Meta Learner",
          "HistGradientBoosting (Best Threshold)",
          "XGBoost (Best Threshold)",
          "Data-based Meta Learner",
          "Single Meta Learner (Stacking)",
          "Final Meta Learner (Meta of Metas)",
          "Days-based Meta Learner",
          "Days-Data Meta Learner"
         ],
         "y": [
          0.1797,
          0.1691,
          0.1628,
          0.1628,
          0.1628,
          0.162,
          0.1561,
          0.1528,
          0.1516,
          0.1442,
          0.1442,
          0.1442
         ],
         "yaxis": "y"
        },
        {
         "marker": {
          "color": "#9467bd"
         },
         "name": "Matthews_CC",
         "offsetgroup": "4",
         "type": "bar",
         "x": [
          "CatBoost (Best Threshold)",
          "Random Forest (Base Threshold)",
          "Age-based Meta Learner",
          "Age-Days Meta Learner",
          "Age-Data Meta Learner",
          "HistGradientBoosting (Best Threshold)",
          "XGBoost (Best Threshold)",
          "Data-based Meta Learner",
          "Single Meta Learner (Stacking)",
          "Final Meta Learner (Meta of Metas)",
          "Days-based Meta Learner",
          "Days-Data Meta Learner"
         ],
         "y": [
          0.1001,
          0.0876,
          0.0744,
          0.0744,
          0.0744,
          0.0737,
          0.0652,
          0.059,
          0.0567,
          0.0479,
          0.0479,
          0.0479
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 600,
        "legend": {
         "orientation": "h",
         "x": 1,
         "xanchor": "right",
         "y": 1.02,
         "yanchor": "bottom"
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Comprehensive Meta Learner Performance Comparison"
        },
        "width": 1200,
        "xaxis": {
         "tickangle": -45,
         "title": {
          "text": "Meta Learner Models"
         }
        },
        "yaxis": {
         "title": {
          "text": "Score"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EVALUATION COMPLETED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Final comparison and visualization\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL COMPARISON OF ALL META LEARNERS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_df = compare_models(results_list)\n",
    "print(comparison_df)\n",
    "\n",
    "# Sort by F1 score\n",
    "comparison_df_sorted = comparison_df.sort('F1', descending=True)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RANKED BY F1 SCORE:\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df_sorted)\n",
    "\n",
    "# Create performance visualization with bar plots\n",
    "fig = go.Figure()\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1', 'Matthews_CC']\n",
    "models = comparison_df_sorted['Model'].to_list()\n",
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    fig.add_trace(go.Bar(\n",
    "        name=metric,\n",
    "        x=models,\n",
    "        y=comparison_df_sorted[metric].to_list(),\n",
    "        marker_color=colors[i],\n",
    "        yaxis='y',\n",
    "        offsetgroup=i\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Comprehensive Meta Learner Performance Comparison',\n",
    "    xaxis_title='Meta Learner Models',\n",
    "    yaxis_title='Score',\n",
    "    barmode='group',  # This ensures bars are grouped, not stacked\n",
    "    height=600,\n",
    "    width=1200,\n",
    "    xaxis_tickangle=-45,\n",
    "    legend=dict(\n",
    "        orientation=\"h\",\n",
    "        yanchor=\"bottom\",\n",
    "        y=1.02,\n",
    "        xanchor=\"right\",\n",
    "        x=1\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EVALUATION COMPLETED!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta-learning evaluation revealed that traditional ensemble methods still outperform complex meta-learning architectures for this customer upselling\n",
    "task. CatBoost with optimized threshold achieved the highest F1-score (0.1797), while Random Forest provided the best balance of recall (0.521) and practical\n",
    "deployment considerations. The sophisticated \"meta of metas\" approach and various segmented meta-learners failed to deliver meaningful improvements over individual\n",
    "optimized base models, suggesting that the additional complexity of hierarchical meta-learning does not justify the marginal or absent performance gains for this\n",
    "specific classification problem. We decided to proceed with Random Forest as our final model due to its superior recall performance (0.521), which is critical for \n",
    "identifying potential upselling opportunities and minimizing missed revenue.m"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magenta-task",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
